# Client Meeting Minutes

- **Start Time:** 4:00 PM
- **End Time:** 5:00 PM
- **Location:** Zoom
- **Date:** October 07, 2022

## Attendance

- Client:
  - Nazim Ragimov (CEO)
  - Erik (developer)

- Team A:
  - Edouard Eltherington
  - Veronica Jack
  - Logan Parker
  - Matt Kuelker

***Attendence Comments***

- Students from other teams present as well

## Client Announcements

- Nazim had a meeting with the professor and determined a schedule for milestones.
- A screenshot of the milestones is provided in the Discord chat

## Agenda Schedule

1. 16:00 TEAM A
2. 16:15 TEAM B
3. 16:30 TEAM C
4. 16:45 Questions and Consult Kukarella's Tech

### TEAM A (16:05)

- View feasibility report for information presented
- Questions from Nazim:
  - Microsoft Azure:
    - Kukarella already has its own TTS
    - This would mean they’re stuck with Microsoft voices? This could be a bad limitation if they’re only available for Microsoft voices
    - They plan to grow and get more providers of voices, even singing
    - Flexibility is important
    - Check with the Rhubarb project to see if it will be maintained or if it risks stopping
    - Specifically requesting a Google integration or one of the other cloud providers (Amazon, Microsoft)
- Erik: we have over 200 Microsoft voices, over 400 voices total
  - They already use Microsoft
  - Use 4 cloud platforms, Google, IBM, Amazon, and Microsoft
  - They have almost the same offerings
  - Azure or Google would be preferred

### TEAM B (16:25)

- Split their group into two: 2D vs 3D
- 2D
  - Image animation in 2D takes time on browser, uses pre-tained libraries, is robotic
  - Generates an MP4, a silhouette, and then creates the silhouette of a face moving, and then anchors the face to the body
  - Can take time and can struggle with larger images, appears robotic
- 3D
  - Already built heads and faces
  - Input from audio, uses libraries and pre-trained models to animate the speaker
  - Found iClone Aids? Commercial and comes at a high cost, but very in-depth and looks very good
  - Found Viseme generation; licensed for non-commercial or research work. More research needed for realism and a good-looking product
- Nazim Questions
  - Work on client side, in browser, through Google Collab
  - Erik, what is preferable?
    - Service-side rather than client-side; API would be better
    - Back-end runs on Amazon EC2

### TEAM C (16:30)

Research on 3 methods:

1. Pre-trained model (Wav2Lip) upload an image or video, audio as well, and generate an output video, roughly 2-min for a 1-min video (scaling). Commercial use has contact info, but no pricing information. No understanding of the limit of length of audio or video.

2. NVIDIA (Audio to face) neural net takes audio source and can sync it to any 3D object. Probably supported for a while, but it will require licensing fees that are not clear. Probably resource-heavy because it requires processing power. Result looks really good. Processing time will probably be heavy as well

3. Lazy KH approach (repo name), maps audio to phonemes and mouth expression. Doesn’t use any kind of deep learning or machine learning. Least computationally expensive. Not uploading an image, so it’s difficult to upload an avatar, but you can have some control (upload a base avatar). User can upload different images and textures, face avatar and mouths and eyes, and then can upload audio and text, and the approach will animate the mouth speaking on the avatar. More difficult with an upload. Very simple to implement, very little processing power, only available on Mac, from 2015, and it’s slow – one-off project but they could optimize it if they take it and customize it

- Nazim: Timing? Time to compute audio to face animations is very quick, but the problem is you need high-end hardware with good computing power. Resources would be quite high.
- Erik: Micro or medium resources currently, nothing insane. The NVIDIA solution might be too heavy. Can always increase computing power or isolate it with an API, Kukarella would need to weigh the options.

### Questions and Consult Kukarella's Tech (16:45)

#### Team Preferences

- TEAM A: We mentioned that the LipGAN approach was our preference
- TEAM B: using libraries to animate still images and overlaying audio
- TEAM C: Split between Wav2Lip and Audio2Face, perhaps making an alternate version of it
- *Note: these preferences may change and will be finalized next week*

#### Final Notes from Client

- Erik:
  - Would like a small written-up report to review in more detail
  - Each team could try a different tech stack
  - Build our app as an API (they have an API server on Node.js on Amazon EC2), JavaScript is good as well
  - If python, then can run an external server for that
  - They will want an API of some kind
  - Their current system does not currently create the timestamps, but they’re working on subtitles
  - The phoneme extraction is all for us to do
  - Audio file format produced by Kukarella app: MP3 and WAV
  - Video file format preferred: MOV and MP4

- Nazim:
  - Some research solutions can come from unexpected places
  - would like us to try different approaches
  - has no preference between 2D and 3D animation, whichever is more realistic and faster to process
  - Nazim found [Google Imagen](https://techcrunch.com/2022/10/05/google-answers-metas-video-generating-ai-with-its-own-dubbed-imagen-video/?utm_source=pocket_mylist) and would like to know if there is a Google approach because of how advanced some of the apps are (creating a video from text)

## To-do List

- Each team chooses what to do (the model/approach) and goes more in-depth requirement and information about where to go from that point
- Share repositories
- Request access to API
- Create an account with an email address and then send the email address to them to receive the Kukarella prime account
- Request access to the SVG images for the avatars on table reads (they also have some characters from their previous mobile app development that has some animation available)
