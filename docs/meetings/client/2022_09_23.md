# Client Meeting Minutes

**Star Time** 4:00 PM <br>
**End Time** 5:00 PM <br>
**Location** FIP 337 <br>
**Date** September 23, 2022

## Attendence

- Client:
    - Nazim Ragimov (CEO)
    - Jasper (developer)

- Team A:
    - Edouard Eltherington
    - Veronica Jack
    - Logan Parker
    - Matt Kuelker

***Attendence Comments***

- Students from other teams present as well

## Agenda Items

<br>

1. **Introductions: Nazim and history of the company**

    - For the last 3 years, their main project's been Kukarella, which was created by UBCO student, Jordan Emsley, in 2 weeks (was a minimal product)
    - As the product gained traction and users, the company's focus shifted and Kukarella became their "exclusive project" which is used for text-to-speech.
    - After about 1 year, they received requests to add a tool for writers to create dialogues with different languages and accents to be used for videos, slide shows, and educational videos.
    - Another project: Audio transcription to be able to transcribe speech from videos
    - Nazim's vision is for people to be able to listen to a lecture, webinar, or even the news and use his company's product to be able to transcribe, listen to, and even communicate with it in real time in multiple languages with a customized avatar (Nazim specifically mentioned "simultaneous dubbing in multiple languages")
    - Technology used is an aggregated model, no synthesis or recognition, so they use technologies created by Google, IBM, Microsoft, and Amazon
    - Before the pandemic, there was little competition, as not many companies were offering this kind of product.
    - During the pandemic, usage went up and now there is a lot more competition with some offering a document importer. Some have different approaches: some allow you to add animation to a still image, while others allow you to use prerecorded video sequences to create animated characters (both can seem creepy, but it's getting better)
    - Nazim's offered Capstone projects before. One project attempted to clone voices, another was a mobile app that allowed the user to send a virtual message to a geographic location, and they were hoping to integrate AR glasses with the app, but the timing was off.

<br>

2. **Define expectations for communication**

    - Expectation is that we'll have weekly meetings, Fridays at 4:00pm, mostly online via Discord with the occasional meeting in person.
    - Nazim and Jasper will create a Discord server and invite us.
    - Jasper is typically quite busy, but we can ask for help in the Discord server; however, he will only answer when he's available so there is no expectation that he will answer us right away.

<br>

3. **Define the project**

    - The project that we will be working on is an application inside of their existing website (Nazim described it as an "add-on")
    - Currently, on the web page, the user "creates an actor" by selecting a voice, language, and avatar. The user enters text, and the current result is an audio file.
    - The goal of our project will be to **add animation to the avatar**
        - animated avatar or animation added to still photo with lips syncing to words
        - User is presented with an embedded video to watch and listen to the resulting animated image with a voice over
    - The user could potentially upload an image for the avatar they want, but Nazim said our prototype could be limited to default avatars that the user can select from the currently existing web app.
    - Nazim requested that we research different approaches (animation vs. still image, 2D vs. 3D) as well as how to ensure the timings for lip syncing is appropriate

<br>

4. **Define milestones, deliverables, and success criteria**

    - Nazim provided our professor with the expected milestones, so we need to follow up about it.
    - Nazim is expecting at least 1 small feature released every 2 weeks
    - There was a misunderstanding of the length of the Capstone Project; Nazim was expecting a prototype of this project completed by Christmas, but it runs until April 2023
    - Success criteria:
        - quick processing
        - realistic lip syncing for different languages
        - compares to competitive software (e.g., www.d-id.com/) or similar programs (https://www.youtube.com/watch?v=y3B8YqeLCpY)

<br>

5. **Requirements gathering**

    *Jasper joined the meeting via Nazim's computer and helped provide information*

    - Since they already have the text-to-speech service, our focus is on the animating the image so that the current product is extended to include an animated video clipe with a face moving
    - Jasper said, "Existing speech API may be usable, but the main interest and focus is how can we create something that gives the user the ability to upload 1-2 images and make it come alive and sync with some audio"
    - Nazim pointed out that it would be easier to work with default avatars (from where the user creates the actor) so we could let the user select the avatar
    
    - After the user submits the avatar, language, voice, and text, the user is presented with a downloadable video with audio

    - The focus is on the back-end application with small front-end to showcase because we will need to create the animation with timings
    
    - Programming language expectations:
        - Back-end is where it would run in the end (currently Node.js with TypeScript, AWS Elastic Beanstalk, etc.)
        - However, as long as the student project program works with requests, there are no restrictions in terms of languages
        - If using Typescript, Jasper recommends to use Prettier for formatting and can provide more information for us to ensure our program is consistent with their standards

    - We will not have much access to their code, and not all API calls are available externally; however, Jasper can provide us with authorization for some requests (i.e., text-to-speech for audio files)

<br>

## Action Items

- Join the Discord Server created by Nazim and Jasper

- Receive information from Jasper regarding formatting, standards, and authorization for externally available API requests

- Research different approaches (animation vs. still image, 2D vs. 3D) as well as how to ensure the timings for lip syncing is appropriate for multiple languages.

- By next meeting, present our research and our plan of what's achievable