# SLIDE CONTENT

# Functional Requirements

Section 2 of the Requirements Report

User must interact with feature through a UI. (Kukerellaâ€™s UI or testing UI) 
Feature must accept both text from the user and audio inputs from the app. 
Feature must produce animation of talking face. Lips must be lip-synced with words. 
Feature would preferably support some form of facial expression 
Any voice selected must be able to be synced to feature animation.
Any language selected must be able to be synced to the feature animation

# PDF CONTENT

Firstly, our user should be able to interact with the feature through a UI. Kukarella has already supplied all of the front-end UI requirements, however for testing our team will use a mock UI. This will assist with user testing and feedback while our codebase is still separate from Kukeralla development. Early testing and examples from other groups proved that lip syncing alone is not enough to produce a convincing animation, and as such facial expressions are required.  The client also noted that any voice or language selected should be able to seamlessly integrate with our animation output. This, along with user text and the generated voice would be required for this feature to work. 
